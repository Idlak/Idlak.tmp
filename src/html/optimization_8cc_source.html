<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>Kaldi: matrix/optimization.cc Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" href="favicon.ico" type="image/x-icon" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="stylesheet.css" rel="stylesheet" type="text/css" /> 
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
 <td id="projectlogo"><a href="http://kaldi-asr.org/"><img alt="Logo" src="KaldiTextAndLogoSmall.png"/ style="padding: 3px 5px 1px 5px"></a></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname" style="display:none">Kaldi
   </div>
  </td>
    <td style="padding-left: 0.5em;">
    <div id="projectbrief" style="display:none"></div>
    </td>
   <!--END PROJECT_BRIEF-->
  <!--END !PROJECT_NAME-->
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('optimization_8cc_source.html','');});
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">optimization.cc</div>  </div>
</div><!--header-->
<div class="contents">
<a href="optimization_8cc.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">// matrix/optimization.cc</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;</div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment">// Copyright 2012  Johns Hopkins University (author: Daniel Povey)</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;</div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment">// See ../../COPYING for clarification regarding multiple authors</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment">// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment">// you may not use this file except in compliance with the License.</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment">// You may obtain a copy of the License at</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment">//  http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment">// THIS CODE IS PROVIDED *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment">// KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment">// WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment">// MERCHANTABLITY OR NON-INFRINGEMENT.</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment">// See the Apache 2 License for the specific language governing permissions and</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;<span class="comment">// limitations under the License.</span></div><div class="line"><a name="l00020"></a><span class="lineno">   20</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;<span class="comment">// (*) incorporates, with permission, FFT code from his book</span></div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;<span class="comment">// &quot;Signal Processing with Lapped Transforms&quot;, Artech, 1992.</span></div><div class="line"><a name="l00023"></a><span class="lineno">   23</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#include &lt;algorithm&gt;</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;</div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="optimization_8h.html">matrix/optimization.h</a>&quot;</span></div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="sp-matrix_8h.html">matrix/sp-matrix.h</a>&quot;</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacekaldi.html">kaldi</a> {</div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="comment">// Below, N&amp;W refers to Nocedal and Wright, &quot;Numerical Optimization&quot;, 2nd Ed.</span></div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00035"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#ac72d44c88e828a4da1a9ecd28551674b">   35</a></span>&#160;<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ac72d44c88e828a4da1a9ecd28551674b">OptimizeLbfgs&lt;Real&gt;::OptimizeLbfgs</a>(<span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;x,</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;                                   <span class="keyword">const</span> <a class="code" href="structkaldi_1_1LbfgsOptions.html">LbfgsOptions</a> &amp;opts):</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;    opts_(opts), k_(0), computation_state_(kBeforeStep), H_was_set_(false) {</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;  <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(opts.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a742204794ea328ba293fe59cec79b990">m</a> &gt; 0); <span class="comment">// dimension.</span></div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;  <a class="code" href="namespacekaldi.html#aac2c220416519a2b0a7ad822ee2ef972">MatrixIndexT</a> dim = x.<a class="code" href="classkaldi_1_1VectorBase.html#af3d58f15749a15d89b0ec5819dd7b7f2">Dim</a>();</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;  <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(dim &gt; 0);</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a> = x; <span class="comment">// this is the value of x_k</span></div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a> = x;  <span class="comment">// this is where we&#39;ll evaluate the function next.</span></div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a4b48e20cbb24328538078a1e3e2e26b5">deriv_</a>.Resize(dim);</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a49414e2a952c937720ac9d86d1a493a6">temp_</a>.Resize(dim);</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a907637141c6924341e62353f8741647e">data_</a>.Resize(2 * opts.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a742204794ea328ba293fe59cec79b990">m</a>, dim);</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#add260d95984af4a4a2e4f62801ee714d">rho_</a>.Resize(opts.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a742204794ea328ba293fe59cec79b990">m</a>);</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;  <span class="comment">// Just set f_ to some invalid value, as we haven&#39;t yet set it.</span></div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a> = (opts.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a> ? 1 : -1 ) * std::numeric_limits&lt;Real&gt;::infinity();</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a562b9272737c7e7d23e33f10c78641b5">best_f_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a>;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a8d06e7592113a02f0e1897b5e8797021">best_x_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>;</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;}</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00055"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#a943e4dc758a32acfcbac5b118bd5c6c5">   55</a></span>&#160;Real <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a943e4dc758a32acfcbac5b118bd5c6c5">OptimizeLbfgs&lt;Real&gt;::RecentStepLength</a>()<span class="keyword"> const </span>{</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;  <span class="keywordtype">size_t</span> <a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a0405ac406512bb982f9d9b4484cbdce2">step_lengths_</a>.size();</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;  <span class="keywordflow">if</span> (n == 0) <span class="keywordflow">return</span> std::numeric_limits&lt;Real&gt;::infinity();</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;  <span class="keywordflow">else</span> {</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;    <span class="keywordflow">if</span> (n &gt;= 2 &amp;&amp; <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a0405ac406512bb982f9d9b4484cbdce2">step_lengths_</a>[n-1] == 0.0 &amp;&amp; <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a0405ac406512bb982f9d9b4484cbdce2">step_lengths_</a>[n-2] == 0.0)</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;      <span class="keywordflow">return</span> 0.0; <span class="comment">// two zeros in a row means repeated restarts, which is</span></div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;    <span class="comment">// a loop.  Short-circuit this by returning zero.</span></div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;    Real avg = 0.0;</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> <a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> = 0; <a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> &lt; <a class="code" href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">n</a>; <a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a>++)</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;      avg += <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a0405ac406512bb982f9d9b4484cbdce2">step_lengths_</a>[<a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a>] / n;</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;    <span class="keywordflow">return</span> avg;</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;  }</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;}</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00070"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#a62dc19c0ed50fa90d11d9d4b70fc4ab7">   70</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a62dc19c0ed50fa90d11d9d4b70fc4ab7">OptimizeLbfgs&lt;Real&gt;::ComputeHifNeeded</a>(<span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;gradient) {</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">k_</a> == 0) {</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afb933c43ae5dd22834f3691b595a119d">H_</a>.Dim() == 0) {</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;      <span class="comment">// H was never set up.  Set it up for the first time.</span></div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;      Real learning_rate;</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;      <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#addac09c44f6617fedf04c2c94b168993">first_step_length</a> &gt; 0.0) { <span class="comment">// this takes</span></div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;        <span class="comment">// precedence over first_step_learning_rate, if set.</span></div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;        <span class="comment">// We are setting up H for the first time.</span></div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;        Real gradient_length = gradient.<a class="code" href="classkaldi_1_1VectorBase.html#acac70fd60afb7fe79533ec35e41d0515">Norm</a>(2.0);</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;        learning_rate = (gradient_length &gt; 0.0 ?</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;                         <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#addac09c44f6617fedf04c2c94b168993">first_step_length</a> / gradient_length :</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;                         1.0);</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;      } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a40a1f514124b3d1cb97835f24cc87196">first_step_impr</a> &gt; 0.0) {</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;        Real gradient_length = gradient.<a class="code" href="classkaldi_1_1VectorBase.html#acac70fd60afb7fe79533ec35e41d0515">Norm</a>(2.0);</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;        learning_rate = (gradient_length &gt; 0.0 ?</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;                  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a40a1f514124b3d1cb97835f24cc87196">first_step_impr</a> / (gradient_length * gradient_length) :</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;                  1.0);</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;      } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;        learning_rate = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a4fb336ce96f3b8b3e93f6ed9545a0fe3">first_step_learning_rate</a>;</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;      }</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;      <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afb933c43ae5dd22834f3691b595a119d">H_</a>.Resize(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>.Dim());</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;      <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(learning_rate &gt; 0.0);</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;      <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afb933c43ae5dd22834f3691b595a119d">H_</a>.Set(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a> ? learning_rate : -learning_rate);</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;    }</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;  } <span class="keywordflow">else</span> { <span class="comment">// k_ &gt; 0</span></div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;    <span class="keywordflow">if</span> (!<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a7bf81985a06cd5dd4bac3d4d6c6651e0">H_was_set_</a>) { <span class="comment">// The user never specified an approximate</span></div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;      <span class="comment">// diagonal inverse Hessian.</span></div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;      <span class="comment">// Set it using formula 7.20: H_k^{(0)} = \gamma_k I, where</span></div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;      <span class="comment">// \gamma_k = s_{k-1}^T y_{k-1} / y_{k-1}^T y_{k-1}</span></div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;      <a class="code" href="classkaldi_1_1SubVector.html">SubVector&lt;Real&gt;</a> y_km1 = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afdde567f86e83f80288c2053a4b800e2">Y</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">k_</a>-1);</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;      <span class="keywordtype">double</span> gamma_k = <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a57f628c0e312973bf4122dd3b05c9dad">S</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">k_</a>-1), y_km1) / <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(y_km1, y_km1);</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;      <span class="keywordflow">if</span> (<a class="code" href="kaldi-math_8h.html#a784e8ae012c86a36a1f764b8ed829746">KALDI_ISNAN</a>(gamma_k) || <a class="code" href="kaldi-math_8h.html#a413ed0dfd2a3120883355aa486da3742">KALDI_ISINF</a>(gamma_k)) {</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;        <a class="code" href="group__error__group.html#ga994be213ddf127b5d6f20a43a02b513a">KALDI_WARN</a> &lt;&lt; <span class="stringliteral">&quot;NaN encountered in L-BFGS (already converged?)&quot;</span>;</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;        gamma_k = (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a> ? 1.0 : -1.0);</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;      }</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;      <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afb933c43ae5dd22834f3691b595a119d">H_</a>.Set(gamma_k);</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;    }</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;  }</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;}  </div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;<span class="comment">// This represents the first 2 lines of Algorithm 7.5 (N&amp;W), which</span></div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;<span class="comment">// in fact is mostly a call to Algorithm 7.4.</span></div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;<span class="comment">// Note: this is valid whether we are minimizing or maximizing.</span></div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00114"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#a3a35596ae2db6104a40d1a1e9f169c0d">  114</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a3a35596ae2db6104a40d1a1e9f169c0d">OptimizeLbfgs&lt;Real&gt;::ComputeNewDirection</a>(Real function_value,</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;                                              <span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;gradient) {</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;  <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aaf567938676e4b091853874074d9188a">computation_state_</a> == <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a172873363491657ec41397989ff61982a2f684fc41b6fbc1c817f00b068e9f6a7">kBeforeStep</a>);</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;  <a class="code" href="namespacekaldi.html#a8408b48db61f80e01de1146a62dc84c1">SignedMatrixIndexT</a> m = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a1e933129f021f099ebf72b95e4af4b07">M</a>(), k = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">k_</a>;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a62dc19c0ed50fa90d11d9d4b70fc4ab7">ComputeHifNeeded</a>(gradient);</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;  <span class="comment">// The rest of this is computing p_k &lt;-- - H_k \nabla f_k using Algorithm</span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;  <span class="comment">// 7.4 of N&amp;W.</span></div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;  <a class="code" href="classkaldi_1_1Vector.html">Vector&lt;Real&gt;</a> &amp;q(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a4b48e20cbb24328538078a1e3e2e26b5">deriv_</a>), &amp;r(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>); <span class="comment">// Use deriv_ as a temporary place to put</span></div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;  <span class="comment">// q, and new_x_ as a temporay place to put r.</span></div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;  <span class="comment">// The if-statement below is just to get rid of spurious warnings from</span></div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;  <span class="comment">// valgrind about memcpy source and destination overlap, since sometimes q and</span></div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;  <span class="comment">// gradient are the same variable.</span></div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;  <span class="keywordflow">if</span> (&amp;q != &amp;gradient)</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;    q.CopyFromVec(gradient); <span class="comment">// q &lt;-- \nabla f_k.</span></div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;  <a class="code" href="classkaldi_1_1Vector.html">Vector&lt;Real&gt;</a> alpha(m);</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;  <span class="comment">// for i = k - 1, k - 2, ... k - m</span></div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="namespacekaldi.html#a8408b48db61f80e01de1146a62dc84c1">SignedMatrixIndexT</a> <a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> = k - 1;</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;       <a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> &gt;= std::max(k - m, static_cast&lt;SignedMatrixIndexT&gt;(0));</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;       <a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a>--) { </div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;    alpha(<a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> % m) = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#add260d95984af4a4a2e4f62801ee714d">rho_</a>(<a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> % m) * <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a57f628c0e312973bf4122dd3b05c9dad">S</a>(<a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a>), q); <span class="comment">// \alpha_i &lt;-- \rho_i s_i^T q.</span></div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;    q.AddVec(-alpha(<a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> % m), <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afdde567f86e83f80288c2053a4b800e2">Y</a>(<a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a>)); <span class="comment">// q &lt;-- q - \alpha_i y_i</span></div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;  }</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;  r.<a class="code" href="classkaldi_1_1VectorBase.html#ae57e5aca5db002545e4b9335c8d9dbfa">SetZero</a>();</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;  r.<a class="code" href="classkaldi_1_1VectorBase.html#a67dde59f2427d653af92c5427babcc21">AddVecVec</a>(1.0, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afb933c43ae5dd22834f3691b595a119d">H_</a>, q, 0.0); <span class="comment">// r &lt;-- H_k^{(0)} q.</span></div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;  <span class="comment">// for k = k - m, k - m + 1, ... , k - 1</span></div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;  <span class="keywordflow">for</span> (<a class="code" href="namespacekaldi.html#a8408b48db61f80e01de1146a62dc84c1">SignedMatrixIndexT</a> <a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> = std::max(k - m, static_cast&lt;SignedMatrixIndexT&gt;(0));</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;       <a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> &lt; k;</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;       <a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a>++) {</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;    Real beta = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#add260d95984af4a4a2e4f62801ee714d">rho_</a>(<a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> % m) * <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afdde567f86e83f80288c2053a4b800e2">Y</a>(<a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a>), r); <span class="comment">// \beta &lt;-- \rho_i y_i^T r</span></div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;    r.<a class="code" href="classkaldi_1_1VectorBase.html#ab109eed73378866c0e8747379378ca44">AddVec</a>(alpha(<a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a> % m) - beta, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a57f628c0e312973bf4122dd3b05c9dad">S</a>(<a class="code" href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">i</a>)); <span class="comment">// r &lt;-- r + s_i (\alpha_i - \beta)</span></div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;  }</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;  { <span class="comment">// TEST.  Note, -r will be the direction.</span></div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    Real dot = <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(gradient, r);</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;    <span class="keywordflow">if</span> ((<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a> &amp;&amp; dot &lt; 0) || (!<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a> &amp;&amp; dot &gt; 0))</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;      <a class="code" href="group__error__group.html#ga994be213ddf127b5d6f20a43a02b513a">KALDI_WARN</a> &lt;&lt; <span class="stringliteral">&quot;Step direction has the wrong sign!  Routine will fail.&quot;</span>;</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;  }</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;  </div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;  <span class="comment">// Now we&#39;re out of Alg. 7.4 and back into Alg. 7.5.</span></div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;  <span class="comment">// Alg. 7.4 returned r (using new_x_ as the location), and with \alpha_k = 1</span></div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;  <span class="comment">// as the initial guess, we&#39;re setting x_{k+1} = x_k + \alpha_k p_k, with</span></div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;  <span class="comment">// p_k = -r [hence the statement new_x_.Scale(-1.0)]., and \alpha_k = 1.</span></div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;  <span class="comment">// This is the first place we&#39;ll get the user to evaluate the function;</span></div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;  <span class="comment">// any backtracking (or acceptance of that step) occurs inside StepSizeIteration.</span></div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;  <span class="comment">// We&#39;re still within iteration k; we haven&#39;t yet finalized the step size.</span></div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>.Scale(-1.0);</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>.AddVec(1.0, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>);</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;  <span class="keywordflow">if</span> (&amp;<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a4b48e20cbb24328538078a1e3e2e26b5">deriv_</a> != &amp;gradient)</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a4b48e20cbb24328538078a1e3e2e26b5">deriv_</a>.CopyFromVec(gradient);</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a> = function_value;</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a260091718af93fbcb88cdd51b7d6aa00">d_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a3fbbd8a3959e76a2bc3455d3bade52dc">d</a>;</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a3f24cedb537f7f6ab88947e84ae6577d">num_wolfe_i_failures_</a> = 0;</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a6fed1c772962340cee1e9c8234971b95">num_wolfe_ii_failures_</a> = 0;</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a9d38960d409b1f5e8d9477c40e0a1a3f">last_failure_type_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a06fc87d81c62e9abb8790b6e5713c55ba634ee767a8e90ff4d56e140459cca31f">kNone</a>;</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aaf567938676e4b091853874074d9188a">computation_state_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a172873363491657ec41397989ff61982a9cb48c363a88e6fb20b60a35bd4a83fa">kWithinStep</a>;</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;}</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00173"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#ab47828aba9fd23fec32ace58bba14a0c">  173</a></span>&#160;<span class="keywordtype">bool</span> <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab47828aba9fd23fec32ace58bba14a0c">OptimizeLbfgs&lt;Real&gt;::AcceptStep</a>(Real function_value,</div><div class="line"><a name="l00174"></a><span class="lineno">  174</span>&#160;                                     <span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;gradient) {</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;  <span class="comment">// Save s_k = x_{k+1} - x_{k}, and y_k = \nabla f_{k+1} - \nabla f_k.</span></div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;  <a class="code" href="classkaldi_1_1SubVector.html">SubVector&lt;Real&gt;</a> s = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a57f628c0e312973bf4122dd3b05c9dad">S</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">k_</a>), y = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afdde567f86e83f80288c2053a4b800e2">Y</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">k_</a>);</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;  s.<a class="code" href="classkaldi_1_1VectorBase.html#a959973067b5f0a4b205c9d8385fa33df">CopyFromVec</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>);</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;  s.<a class="code" href="classkaldi_1_1VectorBase.html#ab109eed73378866c0e8747379378ca44">AddVec</a>(-1.0, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>); <span class="comment">// s = new_x_ - x_.</span></div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;  y.CopyFromVec(gradient);</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;  y.AddVec(-1.0, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a4b48e20cbb24328538078a1e3e2e26b5">deriv_</a>); <span class="comment">// y = gradient - deriv_.</span></div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;  </div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;  <span class="comment">// Warning: there is a division in the next line.  This could</span></div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;  <span class="comment">// generate inf or nan, but this wouldn&#39;t necessarily be an error</span></div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;  <span class="comment">// at this point because for zero step size or derivative we should</span></div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;  <span class="comment">// terminate the iterations.  But this is up to the calling code.</span></div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;  Real prod = <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(y, s);</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#add260d95984af4a4a2e4f62801ee714d">rho_</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">k_</a> % <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a742204794ea328ba293fe59cec79b990">m</a>) = 1.0 / prod;</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;  Real len = s.<a class="code" href="classkaldi_1_1VectorBase.html#acac70fd60afb7fe79533ec35e41d0515">Norm</a>(2.0);</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;  <span class="keywordflow">if</span> ((<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a> &amp;&amp; prod &lt;= 1.0e-20) || (!<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a> &amp;&amp; prod &gt;= -1.0e-20)</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;      || len == 0.0)</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">false</span>; <span class="comment">// This will force restart.</span></div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;  </div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;  <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(3) &lt;&lt; <span class="stringliteral">&quot;Accepted step; length was &quot;</span> &lt;&lt; len</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;                &lt;&lt; <span class="stringliteral">&quot;, prod was &quot;</span> &lt;&lt; prod;</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aff9ed61999b2f3f81f0537ffc3777ac0">RecordStepLength</a>(len);</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;  </div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;  <span class="comment">// store x_{k+1} and the function value f_{k+1}.</span></div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>.CopyFromVec(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>);</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a> = function_value;</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">k_</a>++;</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;</div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;  <span class="keywordflow">return</span> <span class="keyword">true</span>; <span class="comment">// We successfully accepted the step.</span></div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;}</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00207"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#aff9ed61999b2f3f81f0537ffc3777ac0">  207</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aff9ed61999b2f3f81f0537ffc3777ac0">OptimizeLbfgs&lt;Real&gt;::RecordStepLength</a>(Real s) {</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a0405ac406512bb982f9d9b4484cbdce2">step_lengths_</a>.push_back(s);</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a0405ac406512bb982f9d9b4484cbdce2">step_lengths_</a>.size() &gt; <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a19293f5400252e78c488b0ac9a0a66ec">avg_step_length</a>))</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a0405ac406512bb982f9d9b4484cbdce2">step_lengths_</a>.erase(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a0405ac406512bb982f9d9b4484cbdce2">step_lengths_</a>.begin(), <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a0405ac406512bb982f9d9b4484cbdce2">step_lengths_</a>.begin() + 1);</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;}</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00215"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#a2e786e5b35eb73fba6a506aeacbd411c">  215</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a2e786e5b35eb73fba6a506aeacbd411c">OptimizeLbfgs&lt;Real&gt;::Restart</a>(<span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;x,</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;                                  Real f,</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;                                  <span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;gradient) {</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;  <span class="comment">// Note: we will consider restarting (the transition of x_ -&gt; x)</span></div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;  <span class="comment">// as a step, even if it has zero step size.  This is necessary in</span></div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;  <span class="comment">// order for convergence to be detected.</span></div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;  {</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;    <a class="code" href="classkaldi_1_1Vector.html">Vector&lt;Real&gt;</a> &amp;diff(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a49414e2a952c937720ac9d86d1a493a6">temp_</a>);</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;    diff.<a class="code" href="classkaldi_1_1VectorBase.html#a959973067b5f0a4b205c9d8385fa33df">CopyFromVec</a>(x);</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;    diff.<a class="code" href="classkaldi_1_1VectorBase.html#ab109eed73378866c0e8747379378ca44">AddVec</a>(-1.0, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>);</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aff9ed61999b2f3f81f0537ffc3777ac0">RecordStepLength</a>(diff.<a class="code" href="classkaldi_1_1VectorBase.html#acac70fd60afb7fe79533ec35e41d0515">Norm</a>(2.0));</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;  }</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">k_</a> = 0; <span class="comment">// Restart the iterations!  [But note that the Hessian,</span></div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;  <span class="comment">// whatever it was, stays as before.]</span></div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;  <span class="keywordflow">if</span> (&amp;<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a> != &amp;x)</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>.CopyFromVec(x);</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>.CopyFromVec(x);</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a> = f;</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aaf567938676e4b091853874074d9188a">computation_state_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a172873363491657ec41397989ff61982a2f684fc41b6fbc1c817f00b068e9f6a7">kBeforeStep</a>;</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a3a35596ae2db6104a40d1a1e9f169c0d">ComputeNewDirection</a>(f, gradient);</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;}</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00238"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#a93a78db56820b82e663df7c5280833d5">  238</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a93a78db56820b82e663df7c5280833d5">OptimizeLbfgs&lt;Real&gt;::StepSizeIteration</a>(Real function_value,</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;                                            <span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;gradient) {</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;  <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(3) &lt;&lt; <span class="stringliteral">&quot;In step size iteration, function value changed &quot;</span></div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;                &lt;&lt; <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a> &lt;&lt; <span class="stringliteral">&quot; to &quot;</span> &lt;&lt; function_value;</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;  </div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;  <span class="comment">// We&#39;re in some part of the backtracking, and the user is providing</span></div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;  <span class="comment">// the objective function value and gradient.</span></div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;  <span class="comment">// We&#39;re checking two conditions: Wolfe i) [the Armijo rule] and</span></div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;  <span class="comment">// Wolfe ii).</span></div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;  </div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;  <span class="comment">// The Armijo rule (when minimizing) is:</span></div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;  <span class="comment">// f(k_k + \alpha_k p_k) &lt;= f(x_k) + c_1 \alpha_k p_k^T \nabla f(x_k), where</span></div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;  <span class="comment">//  \nabla means the derivative.</span></div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;  <span class="comment">// Below, &quot;temp&quot; is the RHS of this equation, where (\alpha_k p_k) equals</span></div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;  <span class="comment">// (new_x_ - x_); we don&#39;t store \alpha or p_k separately, they are implicit</span></div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;  <span class="comment">// as the difference new_x_ - x_.</span></div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;  <span class="comment">// Below, pf is \alpha_k p_k^T \nabla f(x_k).</span></div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;  Real pf = <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a4b48e20cbb24328538078a1e3e2e26b5">deriv_</a>) - <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a4b48e20cbb24328538078a1e3e2e26b5">deriv_</a>);</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;  Real temp = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a> + <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a7fea4d2f6f3c31b60301494b136558af">c1</a> * pf;</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;  </div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;  <span class="keywordtype">bool</span> wolfe_i_ok;</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a>) wolfe_i_ok = (function_value &lt;= temp);</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;  <span class="keywordflow">else</span> wolfe_i_ok = (function_value &gt;= temp);</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;  </div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;  <span class="comment">// Wolfe condition ii) can be written as:</span></div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;  <span class="comment">//  p_k^T \nabla f(x_k + \alpha_k p_k) &gt;= c_2 p_k^T \nabla f(x_k)</span></div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;  <span class="comment">// p2f equals \alpha_k p_k^T \nabla f(x_k + \alpha_k p_k), where</span></div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;  <span class="comment">// (\alpha_k p_k^T) is (new_x_ - x_).</span></div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;  <span class="comment">// Note that in our version of Wolfe condition (ii) we have an extra</span></div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;  <span class="comment">// factor alpha, which doesn&#39;t affect anything.</span></div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;  Real p2f = <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>, gradient) - <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>, gradient);</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;  <span class="comment">//eps = (sizeof(Real) == 4 ? 1.0e-05 : 1.0e-10) *</span></div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;  <span class="comment">//(std::abs(p2f) + std::abs(pf));</span></div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;  <span class="keywordtype">bool</span> wolfe_ii_ok;</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a>) wolfe_ii_ok = (p2f &gt;= <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a0fe1885b4d10c978f52619ab968adadc">c2</a> * pf);</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;  <span class="keywordflow">else</span> wolfe_ii_ok = (p2f &lt;= <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a0fe1885b4d10c978f52619ab968adadc">c2</a> * pf);</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;  <span class="keyword">enum</span> { kDecrease, kNoChange } d_action; <span class="comment">// What do do with d_: leave it alone,</span></div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;  <span class="comment">// or take the square root.</span></div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;  <span class="keyword">enum</span> { kAccept, kDecreaseStep, kIncreaseStep, kRestart } iteration_action;</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;  <span class="comment">// What we&#39;ll do in the overall iteration: accept this value, DecreaseStep</span></div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;  <span class="comment">// (reduce the step size), IncreaseStep (increase the step size), or kRestart</span></div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;  <span class="comment">// (set k back to zero).  Generally when we can&#39;t get both conditions to be</span></div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;  <span class="comment">// true with a reasonable period of time, it makes sense to restart, because</span></div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;  <span class="comment">// probably we&#39;ve almost converged and got into numerical issues; from here</span></div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;  <span class="comment">// we&#39;ll just produced NaN&#39;s.  Restarting is a safe thing to do and the outer</span></div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;  <span class="comment">// code will quickly detect convergence.</span></div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;  d_action = kNoChange; <span class="comment">// the default.</span></div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;  </div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;  <span class="keywordflow">if</span> (wolfe_i_ok &amp;&amp; wolfe_ii_ok) {</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;    iteration_action = kAccept;</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;    d_action = kNoChange; <span class="comment">// actually doesn&#39;t matter, it&#39;ll get reset.</span></div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;  } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!wolfe_i_ok) {</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;    <span class="comment">// If wolfe i) [the Armijo rule] failed then we went too far (or are</span></div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;    <span class="comment">// meeting numerical problems).</span></div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a9d38960d409b1f5e8d9477c40e0a1a3f">last_failure_type_</a> == <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a06fc87d81c62e9abb8790b6e5713c55bad5a1613937fdc01567ef5cd03fb9801e">kWolfeII</a>) { <span class="comment">// Last time we failed it was Wolfe ii).</span></div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;      <span class="comment">// When we switch between them we decrease d.</span></div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;      d_action = kDecrease;</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;    }</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;    iteration_action = kDecreaseStep;</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a9d38960d409b1f5e8d9477c40e0a1a3f">last_failure_type_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a06fc87d81c62e9abb8790b6e5713c55bab75c46aa0a8c95c4fb9a7917ef095785">kWolfeI</a>;</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a3f24cedb537f7f6ab88947e84ae6577d">num_wolfe_i_failures_</a>++;</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;  } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!wolfe_ii_ok) {</div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;    <span class="comment">// Curvature condition failed -&gt; we did not go far enough.</span></div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a9d38960d409b1f5e8d9477c40e0a1a3f">last_failure_type_</a> == <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a06fc87d81c62e9abb8790b6e5713c55bab75c46aa0a8c95c4fb9a7917ef095785">kWolfeI</a>) <span class="comment">// switching between wolfe i and ii failures-&gt;</span></div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;      d_action = kDecrease; <span class="comment">// decrease value of d.</span></div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;    iteration_action = kIncreaseStep;</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a9d38960d409b1f5e8d9477c40e0a1a3f">last_failure_type_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a06fc87d81c62e9abb8790b6e5713c55bad5a1613937fdc01567ef5cd03fb9801e">kWolfeII</a>;</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a6fed1c772962340cee1e9c8234971b95">num_wolfe_ii_failures_</a>++;</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;  }</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;  <span class="comment">// Test whether we&#39;ve been switching too many times betwen wolfe i) and ii)</span></div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;  <span class="comment">// failures, or overall have an excessive number of failures.  We just give up</span></div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;  <span class="comment">// and restart L-BFGS.  Probably we&#39;ve almost converged.</span></div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a3f24cedb537f7f6ab88947e84ae6577d">num_wolfe_i_failures_</a> + <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a6fed1c772962340cee1e9c8234971b95">num_wolfe_ii_failures_</a> &gt;</div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;      <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a5c8cf12cca09c232c34c197aa2ebb24e">max_line_search_iters</a>) {</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;    <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(2) &lt;&lt; <span class="stringliteral">&quot;Too many steps in line search -&gt; restarting.&quot;</span>;</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;    iteration_action = kRestart;</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;  }</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;  <span class="keywordflow">if</span> (d_action == kDecrease)</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a260091718af93fbcb88cdd51b7d6aa00">d_</a> = std::sqrt(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a260091718af93fbcb88cdd51b7d6aa00">d_</a>);</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;  </div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;  <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(3) &lt;&lt; <span class="stringliteral">&quot;d = &quot;</span> &lt;&lt; <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a260091718af93fbcb88cdd51b7d6aa00">d_</a> &lt;&lt; <span class="stringliteral">&quot;, iter = &quot;</span> &lt;&lt; <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">k_</a> &lt;&lt; <span class="stringliteral">&quot;, action = &quot;</span></div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;                &lt;&lt; (iteration_action == kAccept ? <span class="stringliteral">&quot;accept&quot;</span> :</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;                    (iteration_action == kDecreaseStep ? <span class="stringliteral">&quot;decrease&quot;</span> :</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;                     (iteration_action == kIncreaseStep ? <span class="stringliteral">&quot;increase&quot;</span> :</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;                      <span class="stringliteral">&quot;reject&quot;</span>)));</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;  </div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;  <span class="comment">// Note: even if iteration_action != Restart at this point,</span></div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;  <span class="comment">// some code below may set it to Restart.</span></div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;  <span class="keywordflow">if</span> (iteration_action == kAccept) {</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ab47828aba9fd23fec32ace58bba14a0c">AcceptStep</a>(function_value, gradient)) { <span class="comment">// If we did</span></div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;      <span class="comment">// not detect a problem while accepting the step..</span></div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;      <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aaf567938676e4b091853874074d9188a">computation_state_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a172873363491657ec41397989ff61982a2f684fc41b6fbc1c817f00b068e9f6a7">kBeforeStep</a>;</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;      <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a3a35596ae2db6104a40d1a1e9f169c0d">ComputeNewDirection</a>(function_value, gradient);</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;    } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;      <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(2) &lt;&lt; <span class="stringliteral">&quot;Restarting L-BFGS computation; problem found while &quot;</span></div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;                    &lt;&lt; <span class="stringliteral">&quot;accepting step.&quot;</span>;</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;      iteration_action = kRestart; <span class="comment">// We&#39;ll have to restart now.</span></div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;    }</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;  }</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;  <span class="keywordflow">if</span> (iteration_action == kDecreaseStep || iteration_action == kIncreaseStep) {</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;    Real scale = (iteration_action == kDecreaseStep ? 1.0 / <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a260091718af93fbcb88cdd51b7d6aa00">d_</a> : <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a260091718af93fbcb88cdd51b7d6aa00">d_</a>);</div><div class="line"><a name="l00344"></a><span class="lineno">  344</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a49414e2a952c937720ac9d86d1a493a6">temp_</a>.CopyFromVec(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>);</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>.Scale(scale);</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>.AddVec(1.0 - scale, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>);</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>.ApproxEqual(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a49414e2a952c937720ac9d86d1a493a6">temp_</a>, 0.0)) {</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;      <span class="comment">// Value of new_x_ did not change at all --&gt; we must restart.</span></div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;      <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(3) &lt;&lt; <span class="stringliteral">&quot;Value of x did not change, when taking step; &quot;</span></div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;                    &lt;&lt; <span class="stringliteral">&quot;will restart computation.&quot;</span>;</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;      iteration_action = kRestart;</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;    }</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>.ApproxEqual(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a49414e2a952c937720ac9d86d1a493a6">temp_</a>, 1.0e-08) &amp;&amp;</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;        std::abs(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a> - function_value) &lt; 1.0e-08 *</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;        std::abs(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a>) &amp;&amp; iteration_action == kDecreaseStep) {</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;      <span class="comment">// This is common and due to roundoff.</span></div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;      <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(3) &lt;&lt; <span class="stringliteral">&quot;We appear to be backtracking while we are extremely &quot;</span></div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;                    &lt;&lt; <span class="stringliteral">&quot;close to the old value; restarting.&quot;</span>;</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;      iteration_action = kRestart;</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;    }</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;        </div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;    <span class="keywordflow">if</span> (iteration_action == kDecreaseStep) {</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;      <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a3f24cedb537f7f6ab88947e84ae6577d">num_wolfe_i_failures_</a>++;</div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;      <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a9d38960d409b1f5e8d9477c40e0a1a3f">last_failure_type_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a06fc87d81c62e9abb8790b6e5713c55bab75c46aa0a8c95c4fb9a7917ef095785">kWolfeI</a>;</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;    } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;      <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a6fed1c772962340cee1e9c8234971b95">num_wolfe_ii_failures_</a>++;</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;      <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a9d38960d409b1f5e8d9477c40e0a1a3f">last_failure_type_</a> = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a06fc87d81c62e9abb8790b6e5713c55bad5a1613937fdc01567ef5cd03fb9801e">kWolfeII</a>;</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;    }</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;  }</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;  <span class="keywordflow">if</span> (iteration_action == kRestart) {</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;    <span class="comment">// We want to restart the computation.  If the objf at new_x_ is</span></div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;    <span class="comment">// better than it was at x_, we&#39;ll start at new_x_, else at x_.</span></div><div class="line"><a name="l00373"></a><span class="lineno">  373</span>&#160;    <span class="keywordtype">bool</span> use_newx;</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;    <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a>) use_newx = (function_value &lt; <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a>);</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;    <span class="keywordflow">else</span> use_newx = (function_value &gt; <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a>);</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;    <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(3) &lt;&lt; <span class="stringliteral">&quot;Restarting computation.&quot;</span>;</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;    <span class="keywordflow">if</span> (use_newx) <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a2e786e5b35eb73fba6a506aeacbd411c">Restart</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>, function_value, gradient);</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;    <span class="keywordflow">else</span> <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a2e786e5b35eb73fba6a506aeacbd411c">Restart</a>(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">x_</a>, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">f_</a>, <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a4b48e20cbb24328538078a1e3e2e26b5">deriv_</a>);</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;  }</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;}</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00383"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#ae642c84f808797e9eb30b4c8783b2287">  383</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ae642c84f808797e9eb30b4c8783b2287">OptimizeLbfgs&lt;Real&gt;::DoStep</a>(Real function_value,</div><div class="line"><a name="l00384"></a><span class="lineno">  384</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;gradient) {</div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a> ? function_value &lt; best_f_ : function_value &gt; <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a562b9272737c7e7d23e33f10c78641b5">best_f_</a>) {</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;    best_f_ = function_value;</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a8d06e7592113a02f0e1897b5e8797021">best_x_</a>.CopyFromVec(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>);</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;  }</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aaf567938676e4b091853874074d9188a">computation_state_</a> == <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a172873363491657ec41397989ff61982a2f684fc41b6fbc1c817f00b068e9f6a7">kBeforeStep</a>)</div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a3a35596ae2db6104a40d1a1e9f169c0d">ComputeNewDirection</a>(function_value, gradient);</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;  <span class="keywordflow">else</span> <span class="comment">// kWithinStep{1,2,3}</span></div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a93a78db56820b82e663df7c5280833d5">StepSizeIteration</a>(function_value, gradient);</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;}</div><div class="line"><a name="l00394"></a><span class="lineno">  394</span>&#160;</div><div class="line"><a name="l00395"></a><span class="lineno">  395</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00396"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#a1b3ea447bcd293b6564a72c07680391f">  396</a></span>&#160;<span class="keywordtype">void</span> <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ae642c84f808797e9eb30b4c8783b2287">OptimizeLbfgs&lt;Real&gt;::DoStep</a>(Real function_value,</div><div class="line"><a name="l00397"></a><span class="lineno">  397</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;gradient,</div><div class="line"><a name="l00398"></a><span class="lineno">  398</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;diag_approx_2nd_deriv) {</div><div class="line"><a name="l00399"></a><span class="lineno">  399</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a> ? function_value &lt; best_f_ : function_value &gt; <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a562b9272737c7e7d23e33f10c78641b5">best_f_</a>) {</div><div class="line"><a name="l00400"></a><span class="lineno">  400</span>&#160;    best_f_ = function_value;</div><div class="line"><a name="l00401"></a><span class="lineno">  401</span>&#160;    <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a8d06e7592113a02f0e1897b5e8797021">best_x_</a>.CopyFromVec(<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">new_x_</a>);</div><div class="line"><a name="l00402"></a><span class="lineno">  402</span>&#160;  }</div><div class="line"><a name="l00403"></a><span class="lineno">  403</span>&#160;  <span class="keywordflow">if</span> (<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">opts_</a>.<a class="code" href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">minimize</a>) {</div><div class="line"><a name="l00404"></a><span class="lineno">  404</span>&#160;    <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(diag_approx_2nd_deriv.<a class="code" href="classkaldi_1_1VectorBase.html#a71501acda04fb82ed3ec279ddda43e28">Min</a>() &gt; 0.0);</div><div class="line"><a name="l00405"></a><span class="lineno">  405</span>&#160;  } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00406"></a><span class="lineno">  406</span>&#160;    <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(diag_approx_2nd_deriv.<a class="code" href="classkaldi_1_1VectorBase.html#a6259d05a6903a4c8c9bd72f4bbc116c1">Max</a>() &lt; 0.0);</div><div class="line"><a name="l00407"></a><span class="lineno">  407</span>&#160;  }</div><div class="line"><a name="l00408"></a><span class="lineno">  408</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a7bf81985a06cd5dd4bac3d4d6c6651e0">H_was_set_</a> = <span class="keyword">true</span>;</div><div class="line"><a name="l00409"></a><span class="lineno">  409</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afb933c43ae5dd22834f3691b595a119d">H_</a>.CopyFromVec(diag_approx_2nd_deriv);</div><div class="line"><a name="l00410"></a><span class="lineno">  410</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#afb933c43ae5dd22834f3691b595a119d">H_</a>.InvertElements();</div><div class="line"><a name="l00411"></a><span class="lineno">  411</span>&#160;  <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#ae642c84f808797e9eb30b4c8783b2287">DoStep</a>(function_value, gradient);</div><div class="line"><a name="l00412"></a><span class="lineno">  412</span>&#160;}</div><div class="line"><a name="l00413"></a><span class="lineno">  413</span>&#160;</div><div class="line"><a name="l00414"></a><span class="lineno">  414</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</div><div class="line"><a name="l00415"></a><span class="lineno">  415</span>&#160;<span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a>&amp;</div><div class="line"><a name="l00416"></a><span class="lineno"><a class="line" href="classkaldi_1_1OptimizeLbfgs.html#a0d57d7a459715f6d00d320db7c59d510">  416</a></span>&#160;<a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a0d57d7a459715f6d00d320db7c59d510">OptimizeLbfgs&lt;Real&gt;::GetValue</a>(Real *objf_value)<span class="keyword"> const </span>{</div><div class="line"><a name="l00417"></a><span class="lineno">  417</span>&#160;  <span class="keywordflow">if</span> (objf_value != NULL) *objf_value = <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a562b9272737c7e7d23e33f10c78641b5">best_f_</a>;</div><div class="line"><a name="l00418"></a><span class="lineno">  418</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a8d06e7592113a02f0e1897b5e8797021">best_x_</a>;</div><div class="line"><a name="l00419"></a><span class="lineno">  419</span>&#160;}</div><div class="line"><a name="l00420"></a><span class="lineno">  420</span>&#160;</div><div class="line"><a name="l00421"></a><span class="lineno">  421</span>&#160;<span class="comment">// to compute the alpha, we are minimizing f(x) =  x^T b - 0.5 x_k^T A x_k  along</span></div><div class="line"><a name="l00422"></a><span class="lineno">  422</span>&#160;<span class="comment">// direction p_k... consider alpha</span></div><div class="line"><a name="l00423"></a><span class="lineno">  423</span>&#160;<span class="comment">// d/dx of f(x) = b - A x_k = r.</span></div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;<span class="comment">// Notation based on Sec. 5.1 of Nocedal and Wright</span></div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;<span class="comment">// Computation based on Alg. 5.2 of Nocedal and Wright (Pg. 112)</span></div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;<span class="comment">// Notation (replicated for convenience):</span></div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;<span class="comment">//  To solve Ax=b for x</span></div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;<span class="comment">//  k : current iteration</span></div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;<span class="comment">//  x_k : estimate of x (at iteration k)</span></div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;<span class="comment">//  r_k : residual ( r_k \eqdef A x_k - b )</span></div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;<span class="comment">//  \alpha_k : step size</span></div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;<span class="comment">//  p_k : A-conjugate direction</span></div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;<span class="comment">//  \beta_k  : coefficient used in A-conjugate direction computation for next</span></div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;<span class="comment">//  iteration</span></div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;<span class="comment">//  </span></div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;<span class="comment">//  Algo.  LinearCG(A,b,x_0)</span></div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;<span class="comment">//  ========================</span></div><div class="line"><a name="l00439"></a><span class="lineno">  439</span>&#160;<span class="comment">//  r_0 = Ax_0 - b</span></div><div class="line"><a name="l00440"></a><span class="lineno">  440</span>&#160;<span class="comment">//  p_0 = -r_0</span></div><div class="line"><a name="l00441"></a><span class="lineno">  441</span>&#160;<span class="comment">//  k = 0</span></div><div class="line"><a name="l00442"></a><span class="lineno">  442</span>&#160;<span class="comment">//</span></div><div class="line"><a name="l00443"></a><span class="lineno">  443</span>&#160;<span class="comment">//  while r_k != 0</span></div><div class="line"><a name="l00444"></a><span class="lineno">  444</span>&#160;<span class="comment">//    \alpha_k = (r_k^T  r_k) / (p_k^T  A  p_k)</span></div><div class="line"><a name="l00445"></a><span class="lineno">  445</span>&#160;<span class="comment">//    x_{k+1} = x_k + \alpha_k  p_k;</span></div><div class="line"><a name="l00446"></a><span class="lineno">  446</span>&#160;<span class="comment">//    r_{k+1} = r_k + \alpha_k  A  p_k</span></div><div class="line"><a name="l00447"></a><span class="lineno">  447</span>&#160;<span class="comment">//    \beta_{k+1} = \frac{r_{k+1}^T r_{k+1}}{r_k^T r_K}</span></div><div class="line"><a name="l00448"></a><span class="lineno">  448</span>&#160;<span class="comment">//    p_{k+1} = -r_{k+1} + \beta_{k+1} p_k</span></div><div class="line"><a name="l00449"></a><span class="lineno">  449</span>&#160;<span class="comment">//    k = k + 1</span></div><div class="line"><a name="l00450"></a><span class="lineno">  450</span>&#160;<span class="comment">//  end</span></div><div class="line"><a name="l00451"></a><span class="lineno">  451</span>&#160;</div><div class="line"><a name="l00452"></a><span class="lineno">  452</span>&#160;<span class="keyword">template</span>&lt;<span class="keyword">class</span> Real&gt;</div><div class="line"><a name="l00453"></a><span class="lineno"><a class="line" href="group__matrix__optimization.html#ga80a5e1e3d59608beacf73b3d6eead3ae">  453</a></span>&#160;int32 <a class="code" href="group__matrix__optimization.html#ga80a5e1e3d59608beacf73b3d6eead3ae">LinearCgd</a>(<span class="keyword">const</span> <a class="code" href="structkaldi_1_1LinearCgdOptions.html">LinearCgdOptions</a> &amp;opts,</div><div class="line"><a name="l00454"></a><span class="lineno">  454</span>&#160;                <span class="keyword">const</span> <a class="code" href="classkaldi_1_1SpMatrix.html">SpMatrix&lt;Real&gt;</a> &amp;A,</div><div class="line"><a name="l00455"></a><span class="lineno">  455</span>&#160;                <span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> &amp;b,</div><div class="line"><a name="l00456"></a><span class="lineno">  456</span>&#160;                <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;Real&gt;</a> *x) {</div><div class="line"><a name="l00457"></a><span class="lineno">  457</span>&#160;  <span class="comment">// Initialize the variables</span></div><div class="line"><a name="l00458"></a><span class="lineno">  458</span>&#160;  <span class="comment">//</span></div><div class="line"><a name="l00459"></a><span class="lineno">  459</span>&#160;  int32 <a class="code" href="classkaldi_1_1OptimizeLbfgs.html#a1e933129f021f099ebf72b95e4af4b07">M</a> = A.<a class="code" href="classkaldi_1_1PackedMatrix.html#acd4c9f53536602585f5aff9e8005299a">NumCols</a>();</div><div class="line"><a name="l00460"></a><span class="lineno">  460</span>&#160;</div><div class="line"><a name="l00461"></a><span class="lineno">  461</span>&#160;  <a class="code" href="classkaldi_1_1Matrix.html">Matrix&lt;Real&gt;</a> storage(4, M);</div><div class="line"><a name="l00462"></a><span class="lineno">  462</span>&#160;  <a class="code" href="classkaldi_1_1SubVector.html">SubVector&lt;Real&gt;</a> r(storage, 0), p(storage, 1), Ap(storage, 2), x_orig(storage, 3);</div><div class="line"><a name="l00463"></a><span class="lineno">  463</span>&#160;  p.CopyFromVec(b);</div><div class="line"><a name="l00464"></a><span class="lineno">  464</span>&#160;  p.AddSpVec(-1.0, A, *x, 1.0);  <span class="comment">// p_0 = b - A x_0</span></div><div class="line"><a name="l00465"></a><span class="lineno">  465</span>&#160;  r.AddVec(-1.0, p);  <span class="comment">// r_0 = - p_0</span></div><div class="line"><a name="l00466"></a><span class="lineno">  466</span>&#160;  x_orig.<a class="code" href="classkaldi_1_1VectorBase.html#a959973067b5f0a4b205c9d8385fa33df">CopyFromVec</a>(*x);  <span class="comment">// in case of failure.</span></div><div class="line"><a name="l00467"></a><span class="lineno">  467</span>&#160;  </div><div class="line"><a name="l00468"></a><span class="lineno">  468</span>&#160;  Real r_cur_norm_sq = <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(r, r),</div><div class="line"><a name="l00469"></a><span class="lineno">  469</span>&#160;      r_initial_norm_sq = r_cur_norm_sq,</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;      r_recompute_norm_sq = r_cur_norm_sq;</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;  <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(5) &lt;&lt; <span class="stringliteral">&quot;In linear CG: initial norm-square of residual = &quot;</span></div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;                &lt;&lt; r_initial_norm_sq;</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;  </div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;  <a class="code" href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a>(opts.<a class="code" href="structkaldi_1_1LinearCgdOptions.html#aeb25e26d691b329129ef7e0bf713bd6e">recompute_residual_factor</a> &lt;= 1.0);</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;  Real max_error_sq = std::max&lt;Real&gt;(opts.<a class="code" href="structkaldi_1_1LinearCgdOptions.html#a70d6b72b1643ffa2ed02798b2b8aca83">max_error</a> * opts.<a class="code" href="structkaldi_1_1LinearCgdOptions.html#a70d6b72b1643ffa2ed02798b2b8aca83">max_error</a>,</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;                                     std::numeric_limits&lt;Real&gt;::min()),</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;      residual_factor = opts.<a class="code" href="structkaldi_1_1LinearCgdOptions.html#aeb25e26d691b329129ef7e0bf713bd6e">recompute_residual_factor</a> *</div><div class="line"><a name="l00479"></a><span class="lineno">  479</span>&#160;                        opts.<a class="code" href="structkaldi_1_1LinearCgdOptions.html#aeb25e26d691b329129ef7e0bf713bd6e">recompute_residual_factor</a>,</div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;      inv_residual_factor = 1.0 / residual_factor;</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;  </div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;  <span class="comment">// Note: although from a mathematical point of view the method should converge</span></div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;  <span class="comment">// after M iterations, in practice (due to roundoff) it does not always</span></div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;  <span class="comment">// converge to good precision after that many iterations so we let the maximum</span></div><div class="line"><a name="l00485"></a><span class="lineno">  485</span>&#160;  <span class="comment">// be M + 5 instead.</span></div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;  int32 k = 0;</div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;  for (; k &lt; M + 5 &amp;&amp; k != opts.<a class="code" href="structkaldi_1_1LinearCgdOptions.html#a10868e6d242c077cba75ebc28d74c994">max_iters</a>; k++) {</div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;    <span class="comment">// Note: we&#39;ll break from this loop if we converge sooner due to</span></div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;    <span class="comment">// max_error.</span></div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;    Ap.AddSpVec(1.0, A, p, 0.0);  <span class="comment">// Ap = A p</span></div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;</div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;    <span class="comment">// Below is how the code used to look.</span></div><div class="line"><a name="l00493"></a><span class="lineno">  493</span>&#160;    <span class="comment">// // next line: \alpha_k = (r_k^T r_k) / (p_k^T A p_k)</span></div><div class="line"><a name="l00494"></a><span class="lineno">  494</span>&#160;    <span class="comment">// Real alpha = r_cur_norm_sq / VecVec(p, Ap);</span></div><div class="line"><a name="l00495"></a><span class="lineno">  495</span>&#160;    <span class="comment">// </span></div><div class="line"><a name="l00496"></a><span class="lineno">  496</span>&#160;    <span class="comment">// We changed r_cur_norm_sq below to -VecVec(p, r).  Although this is</span></div><div class="line"><a name="l00497"></a><span class="lineno">  497</span>&#160;    <span class="comment">// slightly less efficient, it seems to make the algorithm dramatically more</span></div><div class="line"><a name="l00498"></a><span class="lineno">  498</span>&#160;    <span class="comment">// robust.  Note that -p^T r is the mathematically more natural quantity to</span></div><div class="line"><a name="l00499"></a><span class="lineno">  499</span>&#160;    <span class="comment">// use here, that corresponds to minimizing along that direction... r^T r is</span></div><div class="line"><a name="l00500"></a><span class="lineno">  500</span>&#160;    <span class="comment">// recommended in Nocedal and Wright only as a kind of optimization as it is</span></div><div class="line"><a name="l00501"></a><span class="lineno">  501</span>&#160;    <span class="comment">// supposed to be the same as -p^T r and we already have it computed.</span></div><div class="line"><a name="l00502"></a><span class="lineno">  502</span>&#160;    Real alpha = -<a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(p, r) / <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(p, Ap);</div><div class="line"><a name="l00503"></a><span class="lineno">  503</span>&#160;    </div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;    <span class="comment">// next line: x_{k+1} = x_k + \alpha_k p_k;</span></div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;    x-&gt;<a class="code" href="classkaldi_1_1VectorBase.html#ab109eed73378866c0e8747379378ca44">AddVec</a>(alpha, p);</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;    <span class="comment">// next line: r_{k+1} = r_k + \alpha_k A p_k</span></div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;    r.AddVec(alpha, Ap);</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;    Real r_next_norm_sq = <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(r, r);</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;    </div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;    <span class="keywordflow">if</span> (r_next_norm_sq &lt; residual_factor * r_recompute_norm_sq ||</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;        r_next_norm_sq &gt; inv_residual_factor * r_recompute_norm_sq) {</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;         </div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;      <span class="comment">// Recompute the residual from scratch if the residual norm has decreased</span></div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;      <span class="comment">// a lot; this costs an extra matrix-vector multiply, but helps keep the</span></div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;      <span class="comment">// residual accurate.</span></div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;      <span class="comment">// Also do the same if the residual norm has increased a lot since</span></div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;      <span class="comment">// the last time we recomputed... this shouldn&#39;t happen often, but</span></div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;      <span class="comment">// it can indicate bad stuff is happening.</span></div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;      </div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;      <span class="comment">// r_{k+1} = A x_{k+1} - b</span></div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;      r.AddSpVec(1.0, A, *x, 0.0);</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;      r.AddVec(-1.0, b);</div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;      r_next_norm_sq = <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(r, r);</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;      r_recompute_norm_sq = r_next_norm_sq;</div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;</div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;      <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(5) &lt;&lt; <span class="stringliteral">&quot;In linear CG: recomputing residual.&quot;</span>;</div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;    }</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;    <a class="code" href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a>(5) &lt;&lt; <span class="stringliteral">&quot;In linear CG: k = &quot;</span> &lt;&lt; k</div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;                  &lt;&lt; <span class="stringliteral">&quot;, r_next_norm_sq = &quot;</span> &lt;&lt; r_next_norm_sq;</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;    <span class="comment">// Check if converged.</span></div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;    <span class="keywordflow">if</span> (r_next_norm_sq &lt;= max_error_sq)</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;      <span class="keywordflow">break</span>;</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;    </div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;    <span class="comment">// next line: \beta_{k+1} = \frac{r_{k+1}^T r_{k+1}}{r_k^T r_K}</span></div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;    Real beta_next = r_next_norm_sq / r_cur_norm_sq;</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;    <span class="comment">// next lines: p_{k+1} = -r_{k+1} + \beta_{k+1} p_k</span></div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;    <a class="code" href="classkaldi_1_1Vector.html">Vector&lt;Real&gt;</a> p_old(p);</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;    p.Scale(beta_next);</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;    p.AddVec(-1.0, r);</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;    r_cur_norm_sq = r_next_norm_sq;</div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;  }</div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;</div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;  <span class="comment">// note: the first element of the &amp;&amp; is only there to save compute.</span></div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;  <span class="comment">// the residual r is A x - b, and r_cur_norm_sq and r_initial_norm_sq are</span></div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;  <span class="comment">// of the form r * r, so it&#39;s clear that b * b has the right dimension to</span></div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;  <span class="comment">// compare with the residual.</span></div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;  <span class="keywordflow">if</span> (r_cur_norm_sq &gt; r_initial_norm_sq &amp;&amp;</div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;      r_cur_norm_sq &gt; r_initial_norm_sq + 1.0e-10 * <a class="code" href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">VecVec</a>(b, b)) {</div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;    <a class="code" href="group__error__group.html#ga994be213ddf127b5d6f20a43a02b513a">KALDI_WARN</a> &lt;&lt; <span class="stringliteral">&quot;Doing linear CGD in dimension &quot;</span> &lt;&lt; A.<a class="code" href="classkaldi_1_1PackedMatrix.html#a01cf7fccddf8deddc75b34408144ded1">NumRows</a>() &lt;&lt; <span class="stringliteral">&quot;, after &quot;</span> &lt;&lt; k</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;              &lt;&lt; <span class="stringliteral">&quot; iterations the squared residual has got worse, &quot;</span></div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;               &lt;&lt; r_cur_norm_sq &lt;&lt; <span class="stringliteral">&quot; &gt; &quot;</span> &lt;&lt; r_initial_norm_sq</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;               &lt;&lt; <span class="stringliteral">&quot;.  Will do an exact optimization.&quot;</span>;</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;    <a class="code" href="structkaldi_1_1SolverOptions.html">SolverOptions</a> opts(<span class="stringliteral">&quot;called-from-linearCGD&quot;</span>);</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;    x-&gt;<a class="code" href="classkaldi_1_1VectorBase.html#a959973067b5f0a4b205c9d8385fa33df">CopyFromVec</a>(x_orig);</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;    <a class="code" href="namespacekaldi.html#a941b06a30750affb2e1d42d5ab78fd99">SolveQuadraticProblem</a>(A, b, opts, x);</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;  }</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;  <span class="keywordflow">return</span> k;</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;} </div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;    </div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;<span class="comment">// Instantiate the class for float and double.</span></div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;<span class="keyword">template</span></div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;<span class="keyword">class </span><a class="code" href="classkaldi_1_1OptimizeLbfgs.html">OptimizeLbfgs&lt;float&gt;</a>;</div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;<span class="keyword">template</span></div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;<span class="keyword">class </span><a class="code" href="classkaldi_1_1OptimizeLbfgs.html">OptimizeLbfgs&lt;double&gt;</a>;</div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;</div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;</div><div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;<span class="keyword">template</span></div><div class="line"><a name="l00568"></a><span class="lineno">  568</span>&#160;int32 <a class="code" href="namespacekaldi.html#acadb55d09ef01d72bafaa77278137b03">LinearCgd&lt;float&gt;</a>(<span class="keyword">const</span> <a class="code" href="structkaldi_1_1LinearCgdOptions.html">LinearCgdOptions</a> &amp;opts,</div><div class="line"><a name="l00569"></a><span class="lineno">  569</span>&#160;                      <span class="keyword">const</span> <a class="code" href="classkaldi_1_1SpMatrix.html">SpMatrix&lt;float&gt;</a> &amp;A, <span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;float&gt;</a> &amp;b,</div><div class="line"><a name="l00570"></a><span class="lineno">  570</span>&#160;                      <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;float&gt;</a> *x);</div><div class="line"><a name="l00571"></a><span class="lineno">  571</span>&#160;</div><div class="line"><a name="l00572"></a><span class="lineno">  572</span>&#160;<span class="keyword">template</span></div><div class="line"><a name="l00573"></a><span class="lineno">  573</span>&#160;int32 <a class="code" href="namespacekaldi.html#a8d006ff62bca8e1e87129da5ebf4763c">LinearCgd&lt;double&gt;</a>(<span class="keyword">const</span> <a class="code" href="structkaldi_1_1LinearCgdOptions.html">LinearCgdOptions</a> &amp;opts,</div><div class="line"><a name="l00574"></a><span class="lineno">  574</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classkaldi_1_1SpMatrix.html">SpMatrix&lt;double&gt;</a> &amp;A, <span class="keyword">const</span> <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;double&gt;</a> &amp;b,</div><div class="line"><a name="l00575"></a><span class="lineno">  575</span>&#160;                        <a class="code" href="classkaldi_1_1VectorBase.html">VectorBase&lt;double&gt;</a> *x);</div><div class="line"><a name="l00576"></a><span class="lineno">  576</span>&#160;</div><div class="line"><a name="l00577"></a><span class="lineno">  577</span>&#160;} <span class="comment">// end namespace kaldi</span></div><div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a7bf81985a06cd5dd4bac3d4d6c6651e0"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a7bf81985a06cd5dd4bac3d4d6c6651e0">kaldi::OptimizeLbfgs::H_was_set_</a></div><div class="ttdeci">bool H_was_set_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00206">optimization.h:206</a></div></div>
<div class="ttc" id="namespacekaldi_html"><div class="ttname"><a href="namespacekaldi.html">kaldi</a></div><div class="ttdoc">Relabels neural network egs with the read pdf-id alignments. </div><div class="ttdef"><b>Definition:</b> <a href="chain_8dox_source.html#l00020">chain.dox:20</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_ace1cb9a15307df924212ace3301dc280"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#ace1cb9a15307df924212ace3301dc280">kaldi::OptimizeLbfgs::x_</a></div><div class="ttdeci">Vector&lt; Real &gt; x_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00210">optimization.h:210</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_ae642c84f808797e9eb30b4c8783b2287"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#ae642c84f808797e9eb30b4c8783b2287">kaldi::OptimizeLbfgs::DoStep</a></div><div class="ttdeci">void DoStep(Real function_value, const VectorBase&lt; Real &gt; &amp;gradient)</div><div class="ttdoc">The user calls this function to provide the class with the function and gradient info at the point Ge...</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00383">optimization.cc:383</a></div></div>
<div class="ttc" id="classkaldi_1_1SpMatrix_html"><div class="ttname"><a href="classkaldi_1_1SpMatrix.html">kaldi::SpMatrix</a></div><div class="ttdoc">Packed symetric matrix class. </div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00062">matrix-common.h:62</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a06fc87d81c62e9abb8790b6e5713c55bab75c46aa0a8c95c4fb9a7917ef095785"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a06fc87d81c62e9abb8790b6e5713c55bab75c46aa0a8c95c4fb9a7917ef095785">kaldi::OptimizeLbfgs::kWolfeI</a></div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00223">optimization.h:223</a></div></div>
<div class="ttc" id="structkaldi_1_1SolverOptions_html"><div class="ttname"><a href="structkaldi_1_1SolverOptions.html">kaldi::SolverOptions</a></div><div class="ttdoc">This class describes the options for maximizing various quadratic objective functions. </div><div class="ttdef"><b>Definition:</b> <a href="sp-matrix_8h_source.html#l00443">sp-matrix.h:443</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a0405ac406512bb982f9d9b4484cbdce2"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a0405ac406512bb982f9d9b4484cbdce2">kaldi::OptimizeLbfgs::step_lengths_</a></div><div class="ttdeci">std::vector&lt; Real &gt; step_lengths_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00232">optimization.h:232</a></div></div>
<div class="ttc" id="sp-matrix_8h_html"><div class="ttname"><a href="sp-matrix_8h.html">sp-matrix.h</a></div></div>
<div class="ttc" id="namespacekaldi_html_a941b06a30750affb2e1d42d5ab78fd99"><div class="ttname"><a href="namespacekaldi.html#a941b06a30750affb2e1d42d5ab78fd99">kaldi::SolveQuadraticProblem</a></div><div class="ttdeci">double SolveQuadraticProblem(const SpMatrix&lt; double &gt; &amp;H, const VectorBase&lt; double &gt; &amp;g, const SolverOptions &amp;opts, VectorBase&lt; double &gt; *x)</div><div class="ttdef"><b>Definition:</b> <a href="sp-matrix_8cc_source.html#l00635">sp-matrix.cc:635</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_aaf567938676e4b091853874074d9188a"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#aaf567938676e4b091853874074d9188a">kaldi::OptimizeLbfgs::computation_state_</a></div><div class="ttdeci">ComputationState computation_state_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00205">optimization.h:205</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a172873363491657ec41397989ff61982a2f684fc41b6fbc1c817f00b068e9f6a7"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a172873363491657ec41397989ff61982a2f684fc41b6fbc1c817f00b068e9f6a7">kaldi::OptimizeLbfgs::kBeforeStep</a></div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00174">optimization.h:174</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a172873363491657ec41397989ff61982a9cb48c363a88e6fb20b60a35bd4a83fa"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a172873363491657ec41397989ff61982a9cb48c363a88e6fb20b60a35bd4a83fa">kaldi::OptimizeLbfgs::kWithinStep</a></div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00175">optimization.h:175</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a2e786e5b35eb73fba6a506aeacbd411c"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a2e786e5b35eb73fba6a506aeacbd411c">kaldi::OptimizeLbfgs::Restart</a></div><div class="ttdeci">void Restart(const VectorBase&lt; Real &gt; &amp;x, Real function_value, const VectorBase&lt; Real &gt; &amp;gradient)</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00215">optimization.cc:215</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a260091718af93fbcb88cdd51b7d6aa00"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a260091718af93fbcb88cdd51b7d6aa00">kaldi::OptimizeLbfgs::d_</a></div><div class="ttdeci">Real d_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00218">optimization.h:218</a></div></div>
<div class="ttc" id="kaldi-math_8h_html_a413ed0dfd2a3120883355aa486da3742"><div class="ttname"><a href="kaldi-math_8h.html#a413ed0dfd2a3120883355aa486da3742">KALDI_ISINF</a></div><div class="ttdeci">#define KALDI_ISINF</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-math_8h_source.html#l00073">kaldi-math.h:73</a></div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html_a5c8cf12cca09c232c34c197aa2ebb24e"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html#a5c8cf12cca09c232c34c197aa2ebb24e">kaldi::LbfgsOptions::max_line_search_iters</a></div><div class="ttdeci">int max_line_search_iters</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00103">optimization.h:103</a></div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html_a4fb336ce96f3b8b3e93f6ed9545a0fe3"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html#a4fb336ce96f3b8b3e93f6ed9545a0fe3">kaldi::LbfgsOptions::first_step_learning_rate</a></div><div class="ttdeci">float first_step_learning_rate</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00087">optimization.h:87</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a0d57d7a459715f6d00d320db7c59d510"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a0d57d7a459715f6d00d320db7c59d510">kaldi::OptimizeLbfgs::GetValue</a></div><div class="ttdeci">const VectorBase&lt; Real &gt; &amp; GetValue(Real *objf_value=NULL) const</div><div class="ttdoc">This returns the value of the variable x that has the best objective function so far, and the corresponding objective function value if requested. </div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00416">optimization.cc:416</a></div></div>
<div class="ttc" id="classkaldi_1_1Matrix_html"><div class="ttname"><a href="classkaldi_1_1Matrix.html">kaldi::Matrix</a></div><div class="ttdoc">A class for storing matrices. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-matrix_8h_source.html#l00777">kaldi-matrix.h:777</a></div></div>
<div class="ttc" id="structkaldi_1_1LinearCgdOptions_html_aeb25e26d691b329129ef7e0bf713bd6e"><div class="ttname"><a href="structkaldi_1_1LinearCgdOptions.html#aeb25e26d691b329129ef7e0bf713bd6e">kaldi::LinearCgdOptions::recompute_residual_factor</a></div><div class="ttdeci">BaseFloat recompute_residual_factor</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00045">optimization.h:45</a></div></div>
<div class="ttc" id="classkaldi_1_1VectorBase_html_a71501acda04fb82ed3ec279ddda43e28"><div class="ttname"><a href="classkaldi_1_1VectorBase.html#a71501acda04fb82ed3ec279ddda43e28">kaldi::VectorBase::Min</a></div><div class="ttdeci">Real Min() const</div><div class="ttdoc">Returns the minimum value of any element, or +infinity for the empty vector. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8cc_source.html#l00619">kaldi-vector.cc:619</a></div></div>
<div class="ttc" id="classkaldi_1_1PackedMatrix_html_a01cf7fccddf8deddc75b34408144ded1"><div class="ttname"><a href="classkaldi_1_1PackedMatrix.html#a01cf7fccddf8deddc75b34408144ded1">kaldi::PackedMatrix::NumRows</a></div><div class="ttdeci">MatrixIndexT NumRows() const</div><div class="ttdef"><b>Definition:</b> <a href="packed-matrix_8h_source.html#l00104">packed-matrix.h:104</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_ab44e2ccef8d27f5b7795c08a3e5d754e"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#ab44e2ccef8d27f5b7795c08a3e5d754e">kaldi::OptimizeLbfgs::k_</a></div><div class="ttdeci">SignedMatrixIndexT k_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00202">optimization.h:202</a></div></div>
<div class="ttc" id="classkaldi_1_1VectorBase_html_acac70fd60afb7fe79533ec35e41d0515"><div class="ttname"><a href="classkaldi_1_1VectorBase.html#acac70fd60afb7fe79533ec35e41d0515">kaldi::VectorBase::Norm</a></div><div class="ttdeci">Real Norm(Real p) const</div><div class="ttdoc">Compute the p-th norm of the vector. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8cc_source.html#l00517">kaldi-vector.cc:517</a></div></div>
<div class="ttc" id="optimization_8h_html"><div class="ttname"><a href="optimization_8h.html">optimization.h</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a49414e2a952c937720ac9d86d1a493a6"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a49414e2a952c937720ac9d86d1a493a6">kaldi::OptimizeLbfgs::temp_</a></div><div class="ttdeci">Vector&lt; Real &gt; temp_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00215">optimization.h:215</a></div></div>
<div class="ttc" id="namespacekaldi_html_acadb55d09ef01d72bafaa77278137b03"><div class="ttname"><a href="namespacekaldi.html#acadb55d09ef01d72bafaa77278137b03">kaldi::LinearCgd&lt; float &gt;</a></div><div class="ttdeci">template int32 LinearCgd&lt; float &gt;(const LinearCgdOptions &amp;opts, const SpMatrix&lt; float &gt; &amp;A, const VectorBase&lt; float &gt; &amp;b, VectorBase&lt; float &gt; *x)</div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html_a3fbbd8a3959e76a2bc3455d3bade52dc"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html#a3fbbd8a3959e76a2bc3455d3bade52dc">kaldi::LbfgsOptions::d</a></div><div class="ttdeci">float d</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00101">optimization.h:101</a></div></div>
<div class="ttc" id="classkaldi_1_1VectorBase_html_a67dde59f2427d653af92c5427babcc21"><div class="ttname"><a href="classkaldi_1_1VectorBase.html#a67dde59f2427d653af92c5427babcc21">kaldi::VectorBase::AddVecVec</a></div><div class="ttdeci">void AddVecVec(Real alpha, const VectorBase&lt; Real &gt; &amp;v, const VectorBase&lt; Real &gt; &amp;r, Real beta)</div><div class="ttdoc">Add element-by-element product of vectlrs: </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8cc_source.html#l00999">kaldi-vector.cc:999</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_ac72d44c88e828a4da1a9ecd28551674b"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#ac72d44c88e828a4da1a9ecd28551674b">kaldi::OptimizeLbfgs::OptimizeLbfgs</a></div><div class="ttdeci">OptimizeLbfgs(const VectorBase&lt; Real &gt; &amp;x, const LbfgsOptions &amp;opts)</div><div class="ttdoc">Initializer takes the starting value of x. </div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00035">optimization.cc:35</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a9d38960d409b1f5e8d9477c40e0a1a3f"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a9d38960d409b1f5e8d9477c40e0a1a3f">kaldi::OptimizeLbfgs::last_failure_type_</a></div><div class="ttdeci">enum kaldi::OptimizeLbfgs::@0 last_failure_type_</div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a99f7ee87e8f40de9970c6b41e76693a4"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a99f7ee87e8f40de9970c6b41e76693a4">kaldi::OptimizeLbfgs::f_</a></div><div class="ttdeci">Real f_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00216">optimization.h:216</a></div></div>
<div class="ttc" id="classkaldi_1_1VectorBase_html_a959973067b5f0a4b205c9d8385fa33df"><div class="ttname"><a href="classkaldi_1_1VectorBase.html#a959973067b5f0a4b205c9d8385fa33df">kaldi::VectorBase::CopyFromVec</a></div><div class="ttdeci">void CopyFromVec(const VectorBase&lt; Real &gt; &amp;v)</div><div class="ttdoc">Copy data from another vector (must match own size). </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8cc_source.html#l00228">kaldi-vector.cc:228</a></div></div>
<div class="ttc" id="classkaldi_1_1PackedMatrix_html_acd4c9f53536602585f5aff9e8005299a"><div class="ttname"><a href="classkaldi_1_1PackedMatrix.html#acd4c9f53536602585f5aff9e8005299a">kaldi::PackedMatrix::NumCols</a></div><div class="ttdeci">MatrixIndexT NumCols() const</div><div class="ttdef"><b>Definition:</b> <a href="packed-matrix_8h_source.html#l00105">packed-matrix.h:105</a></div></div>
<div class="ttc" id="namespacekaldi_html_aac2c220416519a2b0a7ad822ee2ef972"><div class="ttname"><a href="namespacekaldi.html#aac2c220416519a2b0a7ad822ee2ef972">kaldi::MatrixIndexT</a></div><div class="ttdeci">int32 MatrixIndexT</div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00098">matrix-common.h:98</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a57f628c0e312973bf4122dd3b05c9dad"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a57f628c0e312973bf4122dd3b05c9dad">kaldi::OptimizeLbfgs::S</a></div><div class="ttdeci">SubVector&lt; Real &gt; S(MatrixIndexT i)</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00184">optimization.h:184</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a06fc87d81c62e9abb8790b6e5713c55bad5a1613937fdc01567ef5cd03fb9801e"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a06fc87d81c62e9abb8790b6e5713c55bad5a1613937fdc01567ef5cd03fb9801e">kaldi::OptimizeLbfgs::kWolfeII</a></div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00223">optimization.h:223</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a562b9272737c7e7d23e33f10c78641b5"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a562b9272737c7e7d23e33f10c78641b5">kaldi::OptimizeLbfgs::best_f_</a></div><div class="ttdeci">Real best_f_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00217">optimization.h:217</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a4b48e20cbb24328538078a1e3e2e26b5"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a4b48e20cbb24328538078a1e3e2e26b5">kaldi::OptimizeLbfgs::deriv_</a></div><div class="ttdeci">Vector&lt; Real &gt; deriv_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00214">optimization.h:214</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_ad94eae02f73af4763eaf2793e81d2373"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#ad94eae02f73af4763eaf2793e81d2373">kaldi::OptimizeLbfgs::new_x_</a></div><div class="ttdeci">Vector&lt; Real &gt; new_x_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00211">optimization.h:211</a></div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html_addac09c44f6617fedf04c2c94b168993"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html#addac09c44f6617fedf04c2c94b168993">kaldi::LbfgsOptions::first_step_length</a></div><div class="ttdeci">float first_step_length</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00090">optimization.h:90</a></div></div>
<div class="ttc" id="namespacernnlm_html_ab4871778d570f724a07823e0a2fb9884"><div class="ttname"><a href="namespacernnlm.html#ab4871778d570f724a07823e0a2fb9884">rnnlm::n</a></div><div class="ttdeci">struct rnnlm::@11::@12 n</div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_afb933c43ae5dd22834f3691b595a119d"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#afb933c43ae5dd22834f3691b595a119d">kaldi::OptimizeLbfgs::H_</a></div><div class="ttdeci">Vector&lt; Real &gt; H_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00226">optimization.h:226</a></div></div>
<div class="ttc" id="classkaldi_1_1VectorBase_html_a6259d05a6903a4c8c9bd72f4bbc116c1"><div class="ttname"><a href="classkaldi_1_1VectorBase.html#a6259d05a6903a4c8c9bd72f4bbc116c1">kaldi::VectorBase::Max</a></div><div class="ttdeci">Real Max() const</div><div class="ttdoc">Returns the maximum value of any element, or -infinity for the empty vector. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8cc_source.html#l00579">kaldi-vector.cc:579</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a6fed1c772962340cee1e9c8234971b95"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a6fed1c772962340cee1e9c8234971b95">kaldi::OptimizeLbfgs::num_wolfe_ii_failures_</a></div><div class="ttdeci">int num_wolfe_ii_failures_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00222">optimization.h:222</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a93a78db56820b82e663df7c5280833d5"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a93a78db56820b82e663df7c5280833d5">kaldi::OptimizeLbfgs::StepSizeIteration</a></div><div class="ttdeci">void StepSizeIteration(Real function_value, const VectorBase&lt; Real &gt; &amp;gradient)</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00238">optimization.cc:238</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html">kaldi::OptimizeLbfgs</a></div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00121">optimization.h:121</a></div></div>
<div class="ttc" id="group__error__group_html_ga994be213ddf127b5d6f20a43a02b513a"><div class="ttname"><a href="group__error__group.html#ga994be213ddf127b5d6f20a43a02b513a">KALDI_WARN</a></div><div class="ttdeci">#define KALDI_WARN</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-error_8h_source.html#l00129">kaldi-error.h:129</a></div></div>
<div class="ttc" id="structkaldi_1_1LinearCgdOptions_html"><div class="ttname"><a href="structkaldi_1_1LinearCgdOptions.html">kaldi::LinearCgdOptions</a></div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00037">optimization.h:37</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_aa0d518b4cade2bda243a4f266f93260a"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#aa0d518b4cade2bda243a4f266f93260a">kaldi::OptimizeLbfgs::opts_</a></div><div class="ttdeci">LbfgsOptions opts_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00201">optimization.h:201</a></div></div>
<div class="ttc" id="classkaldi_1_1VectorBase_html_af3d58f15749a15d89b0ec5819dd7b7f2"><div class="ttname"><a href="classkaldi_1_1VectorBase.html#af3d58f15749a15d89b0ec5819dd7b7f2">kaldi::VectorBase::Dim</a></div><div class="ttdeci">MatrixIndexT Dim() const</div><div class="ttdoc">Returns the dimension of the vector. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8h_source.html#l00063">kaldi-vector.h:63</a></div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html_a13cea48cd71e919b6b515279c984fabf"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html#a13cea48cd71e919b6b515279c984fabf">kaldi::LbfgsOptions::minimize</a></div><div class="ttdeci">bool minimize</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00085">optimization.h:85</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a1e933129f021f099ebf72b95e4af4b07"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a1e933129f021f099ebf72b95e4af4b07">kaldi::OptimizeLbfgs::M</a></div><div class="ttdeci">MatrixIndexT M()</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00180">optimization.h:180</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_aff9ed61999b2f3f81f0537ffc3777ac0"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#aff9ed61999b2f3f81f0537ffc3777ac0">kaldi::OptimizeLbfgs::RecordStepLength</a></div><div class="ttdeci">void RecordStepLength(Real s)</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00207">optimization.cc:207</a></div></div>
<div class="ttc" id="structkaldi_1_1LinearCgdOptions_html_a10868e6d242c077cba75ebc28d74c994"><div class="ttname"><a href="structkaldi_1_1LinearCgdOptions.html#a10868e6d242c077cba75ebc28d74c994">kaldi::LinearCgdOptions::max_iters</a></div><div class="ttdeci">int32 max_iters</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00038">optimization.h:38</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a943e4dc758a32acfcbac5b118bd5c6c5"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a943e4dc758a32acfcbac5b118bd5c6c5">kaldi::OptimizeLbfgs::RecentStepLength</a></div><div class="ttdeci">Real RecentStepLength() const</div><div class="ttdoc">Returns the average magnitude of the last n steps (but not more than the number we have stored)...</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00055">optimization.cc:55</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a3f24cedb537f7f6ab88947e84ae6577d"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a3f24cedb537f7f6ab88947e84ae6577d">kaldi::OptimizeLbfgs::num_wolfe_i_failures_</a></div><div class="ttdeci">int num_wolfe_i_failures_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00221">optimization.h:221</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a06fc87d81c62e9abb8790b6e5713c55ba634ee767a8e90ff4d56e140459cca31f"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a06fc87d81c62e9abb8790b6e5713c55ba634ee767a8e90ff4d56e140459cca31f">kaldi::OptimizeLbfgs::kNone</a></div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00223">optimization.h:223</a></div></div>
<div class="ttc" id="namespacekaldi_html_a8d006ff62bca8e1e87129da5ebf4763c"><div class="ttname"><a href="namespacekaldi.html#a8d006ff62bca8e1e87129da5ebf4763c">kaldi::LinearCgd&lt; double &gt;</a></div><div class="ttdeci">template int32 LinearCgd&lt; double &gt;(const LinearCgdOptions &amp;opts, const SpMatrix&lt; double &gt; &amp;A, const VectorBase&lt; double &gt; &amp;b, VectorBase&lt; double &gt; *x)</div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html_a742204794ea328ba293fe59cec79b990"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html#a742204794ea328ba293fe59cec79b990">kaldi::LbfgsOptions::m</a></div><div class="ttdeci">int m</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00086">optimization.h:86</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a62dc19c0ed50fa90d11d9d4b70fc4ab7"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a62dc19c0ed50fa90d11d9d4b70fc4ab7">kaldi::OptimizeLbfgs::ComputeHifNeeded</a></div><div class="ttdeci">void ComputeHifNeeded(const VectorBase&lt; Real &gt; &amp;gradient)</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00070">optimization.cc:70</a></div></div>
<div class="ttc" id="structkaldi_1_1LinearCgdOptions_html_a70d6b72b1643ffa2ed02798b2b8aca83"><div class="ttname"><a href="structkaldi_1_1LinearCgdOptions.html#a70d6b72b1643ffa2ed02798b2b8aca83">kaldi::LinearCgdOptions::max_error</a></div><div class="ttdeci">BaseFloat max_error</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00039">optimization.h:39</a></div></div>
<div class="ttc" id="namespacernnlm_html_acb559820d9ca11295b4500f179ef6392"><div class="ttname"><a href="namespacernnlm.html#acb559820d9ca11295b4500f179ef6392">rnnlm::i</a></div><div class="ttdeci">int i</div><div class="ttdef"><b>Definition:</b> <a href="mikolov-rnnlm-lib_8cc_source.html#l00066">mikolov-rnnlm-lib.cc:66</a></div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html_a40a1f514124b3d1cb97835f24cc87196"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html#a40a1f514124b3d1cb97835f24cc87196">kaldi::LbfgsOptions::first_step_impr</a></div><div class="ttdeci">float first_step_impr</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00094">optimization.h:94</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a8d06e7592113a02f0e1897b5e8797021"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a8d06e7592113a02f0e1897b5e8797021">kaldi::OptimizeLbfgs::best_x_</a></div><div class="ttdeci">Vector&lt; Real &gt; best_x_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00212">optimization.h:212</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_afdde567f86e83f80288c2053a4b800e2"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#afdde567f86e83f80288c2053a4b800e2">kaldi::OptimizeLbfgs::Y</a></div><div class="ttdeci">SubVector&lt; Real &gt; Y(MatrixIndexT i)</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00181">optimization.h:181</a></div></div>
<div class="ttc" id="classkaldi_1_1Vector_html"><div class="ttname"><a href="classkaldi_1_1Vector.html">kaldi::Vector</a></div><div class="ttdoc">A class representing a vector. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8h_source.html#l00390">kaldi-vector.h:390</a></div></div>
<div class="ttc" id="kaldi-math_8h_html_a784e8ae012c86a36a1f764b8ed829746"><div class="ttname"><a href="kaldi-math_8h.html#a784e8ae012c86a36a1f764b8ed829746">KALDI_ISNAN</a></div><div class="ttdeci">#define KALDI_ISNAN</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-math_8h_source.html#l00072">kaldi-math.h:72</a></div></div>
<div class="ttc" id="namespacekaldi_html_a8408b48db61f80e01de1146a62dc84c1"><div class="ttname"><a href="namespacekaldi.html#a8408b48db61f80e01de1146a62dc84c1">kaldi::SignedMatrixIndexT</a></div><div class="ttdeci">int32 SignedMatrixIndexT</div><div class="ttdef"><b>Definition:</b> <a href="matrix-common_8h_source.html#l00099">matrix-common.h:99</a></div></div>
<div class="ttc" id="group__error__group_html_gad5710173d69cddcda4fa21ded3c77f16"><div class="ttname"><a href="group__error__group.html#gad5710173d69cddcda4fa21ded3c77f16">KALDI_ASSERT</a></div><div class="ttdeci">#define KALDI_ASSERT(cond)</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-error_8h_source.html#l00168">kaldi-error.h:168</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a3a35596ae2db6104a40d1a1e9f169c0d"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a3a35596ae2db6104a40d1a1e9f169c0d">kaldi::OptimizeLbfgs::ComputeNewDirection</a></div><div class="ttdeci">void ComputeNewDirection(Real function_value, const VectorBase&lt; Real &gt; &amp;gradient)</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00114">optimization.cc:114</a></div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html_a19293f5400252e78c488b0ac9a0a66ec"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html#a19293f5400252e78c488b0ac9a0a66ec">kaldi::LbfgsOptions::avg_step_length</a></div><div class="ttdeci">int avg_step_length</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00104">optimization.h:104</a></div></div>
<div class="ttc" id="group__matrix__optimization_html_ga80a5e1e3d59608beacf73b3d6eead3ae"><div class="ttname"><a href="group__matrix__optimization.html#ga80a5e1e3d59608beacf73b3d6eead3ae">kaldi::LinearCgd</a></div><div class="ttdeci">int32 LinearCgd(const LinearCgdOptions &amp;opts, const SpMatrix&lt; Real &gt; &amp;A, const VectorBase&lt; Real &gt; &amp;b, VectorBase&lt; Real &gt; *x)</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00453">optimization.cc:453</a></div></div>
<div class="ttc" id="group__error__group_html_ga16c81ec6ff3ba04c6ff96fdaed9d854e"><div class="ttname"><a href="group__error__group.html#ga16c81ec6ff3ba04c6ff96fdaed9d854e">KALDI_VLOG</a></div><div class="ttdeci">#define KALDI_VLOG(v)</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-error_8h_source.html#l00135">kaldi-error.h:135</a></div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html_a0fe1885b4d10c978f52619ab968adadc"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html#a0fe1885b4d10c978f52619ab968adadc">kaldi::LbfgsOptions::c2</a></div><div class="ttdeci">float c2</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00100">optimization.h:100</a></div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html_a7fea4d2f6f3c31b60301494b136558af"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html#a7fea4d2f6f3c31b60301494b136558af">kaldi::LbfgsOptions::c1</a></div><div class="ttdeci">float c1</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00099">optimization.h:99</a></div></div>
<div class="ttc" id="structkaldi_1_1LbfgsOptions_html"><div class="ttname"><a href="structkaldi_1_1LbfgsOptions.html">kaldi::LbfgsOptions</a></div><div class="ttdoc">This is an implementation of L-BFGS. </div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00084">optimization.h:84</a></div></div>
<div class="ttc" id="classkaldi_1_1VectorBase_html"><div class="ttname"><a href="classkaldi_1_1VectorBase.html">kaldi::VectorBase</a></div><div class="ttdoc">Provides a vector abstraction class. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8h_source.html#l00040">kaldi-vector.h:40</a></div></div>
<div class="ttc" id="classkaldi_1_1VectorBase_html_ae57e5aca5db002545e4b9335c8d9dbfa"><div class="ttname"><a href="classkaldi_1_1VectorBase.html#ae57e5aca5db002545e4b9335c8d9dbfa">kaldi::VectorBase::SetZero</a></div><div class="ttdeci">void SetZero()</div><div class="ttdoc">Set vector to all zeros. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8cc_source.html#l00288">kaldi-vector.cc:288</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_ab47828aba9fd23fec32ace58bba14a0c"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#ab47828aba9fd23fec32ace58bba14a0c">kaldi::OptimizeLbfgs::AcceptStep</a></div><div class="ttdeci">bool AcceptStep(Real function_value, const VectorBase&lt; Real &gt; &amp;gradient)</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8cc_source.html#l00173">optimization.cc:173</a></div></div>
<div class="ttc" id="group__matrix__funcs__scalar_html_ga4750cd6f7a02a013435779588056b153"><div class="ttname"><a href="group__matrix__funcs__scalar.html#ga4750cd6f7a02a013435779588056b153">kaldi::VecVec</a></div><div class="ttdeci">Real VecVec(const VectorBase&lt; Real &gt; &amp;a, const VectorBase&lt; Real &gt; &amp;b)</div><div class="ttdoc">Returns dot product between v1 and v2. </div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8cc_source.html#l00037">kaldi-vector.cc:37</a></div></div>
<div class="ttc" id="classkaldi_1_1VectorBase_html_ab109eed73378866c0e8747379378ca44"><div class="ttname"><a href="classkaldi_1_1VectorBase.html#ab109eed73378866c0e8747379378ca44">kaldi::VectorBase::AddVec</a></div><div class="ttdeci">void AddVec(const Real alpha, const VectorBase&lt; OtherReal &gt; &amp;v)</div><div class="ttdoc">Add vector : *this = *this + alpha * rv (with casting between floats and doubles) ...</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8cc_source.html#l01043">kaldi-vector.cc:1043</a></div></div>
<div class="ttc" id="classkaldi_1_1SubVector_html"><div class="ttname"><a href="classkaldi_1_1SubVector.html">kaldi::SubVector</a></div><div class="ttdoc">Represents a non-allocating general vector which can be defined as a sub-vector of higher-level vecto...</div><div class="ttdef"><b>Definition:</b> <a href="kaldi-vector_8h_source.html#l00485">kaldi-vector.h:485</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_add260d95984af4a4a2e4f62801ee714d"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#add260d95984af4a4a2e4f62801ee714d">kaldi::OptimizeLbfgs::rho_</a></div><div class="ttdeci">Vector&lt; Real &gt; rho_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00230">optimization.h:230</a></div></div>
<div class="ttc" id="classkaldi_1_1OptimizeLbfgs_html_a907637141c6924341e62353f8741647e"><div class="ttname"><a href="classkaldi_1_1OptimizeLbfgs.html#a907637141c6924341e62353f8741647e">kaldi::OptimizeLbfgs::data_</a></div><div class="ttdeci">Matrix&lt; Real &gt; data_</div><div class="ttdef"><b>Definition:</b> <a href="optimization_8h_source.html#l00228">optimization.h:228</a></div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="dir_109f68d84cef4a133396a0be144fa9b1.html">matrix</a></li><li class="navelem"><a class="el" href="optimization_8cc.html">optimization.cc</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.13 </li>
  </ul>
</div>
</body>
</html>
